#!/usr/bin/env python3
"""
ğŸ§ª JAPANESE QUIZ SOLVER ACCURACY TEST ğŸ§ª
Comprehensive testing script to validate answer accuracy and performance.
"""

import sys
import time
from datetime import datetime
from typing import Dict, List, Tuple, Optional

# Import our solver
from ultimate_main import UltimateQuizSolver

class AccuracyTester:
    """Test suite for Japanese quiz solver accuracy"""
    
    def __init__(self):
        self.solver = UltimateQuizSolver()
        self.test_results = []
        
    def run_test_case(self, question_text: str, expected_answer: str, test_name: str) -> Dict:
        """Run a single test case and return results"""
        print(f"\nğŸ§ª Testing: {test_name}")
        print(f"ğŸ“ Question: {question_text}")
        print(f"âœ… Expected: {expected_answer}")
        
        start_time = time.time()
        
        # Get AI answer
        ai_response, provider, processing_time = self.solver.get_ai_answer(question_text)
        
        # Extract actual answer from AI response
        actual_answer = self.extract_answer_from_response(ai_response)
        
        # Check if correct
        is_correct = self.is_answer_correct(actual_answer, expected_answer)
        
        total_time = time.time() - start_time
        
        result = {
            "test_name": test_name,
            "question": question_text,
            "expected": expected_answer,
            "actual": actual_answer,
            "ai_response": ai_response,
            "is_correct": is_correct,
            "processing_time": processing_time,
            "total_time": total_time,
            "provider": provider
        }
        
        self.test_results.append(result)
        
        status = "âœ… CORRECT" if is_correct else "âŒ INCORRECT"
        print(f"ğŸ¯ Actual: {actual_answer}")
        print(f"âš¡ Result: {status} ({processing_time:.2f}s)")
        
        return result
    
    def extract_answer_from_response(self, response: str) -> str:
        """Extract the answer from AI response"""
        lines = response.split('\n')
        for line in lines:
            if line.strip().startswith('ğŸ¯ ANSWER:'):
                answer = line.replace('ğŸ¯ ANSWER:', '').strip()
                # Clean up answer format
                answer = answer.split(',')[0].strip()  # Take first answer if multiple
                answer = answer.split(' ')[0].strip()  # Take first part
                return answer
        return "NO_ANSWER_FOUND"
    
    def is_answer_correct(self, actual: str, expected: str) -> bool:
        """Check if the actual answer matches expected"""
        actual_clean = actual.strip().lower()
        expected_clean = expected.strip().lower()
        
        # Direct match
        if actual_clean == expected_clean:
            return True
        
        # Check if actual contains expected (for multiple choice symbols)
        if expected_clean in actual_clean or actual_clean in expected_clean:
            return True
        
        # Check for common variations
        variations = {
            'â‘ ': ['1', 'ichi', 'first'],
            'â‘¡': ['2', 'ni', 'second'],
            'â‘¢': ['3', 'san', 'third'],
            'â‘£': ['4', 'yon', 'fourth'],
            'â‘¤': ['5', 'go', 'fifth']
        }
        
        for symbol, alts in variations.items():
            if (expected_clean == symbol and actual_clean in alts) or \
               (actual_clean == symbol and expected_clean in alts):
                return True
        
        return False
    
    def run_comprehensive_tests(self):
        """Run comprehensive test suite"""
        print("\nğŸ¯ ULTIMATE JAPANESE QUIZ SOLVER - ACCURACY TEST SUITE ğŸ¯")
        print("=" * 70)
        
        # Test cases based on common JLPT patterns
        test_cases = [
            # Basic vocabulary tests
            {
                "question": "ã¯ã¯ã¨ã€€ã‚„ã¾ã«ã€€ã®ã¼ã‚Šã¾ã—ãŸã€‚(16). ã¯ã¯ã€€â‘ .å¨ ã€€â‘¡.åµã€€â‘¢.å¥´ã€€â‘£.æ¯",
                "expected": "â‘£",
                "test_name": "Basic Vocabulary - Mother (æ¯)"
            },
            {
                "question": "ã¯ã¯ã¨ã€€ã‚„ã¾ã«ã€€ã®ã¼ã‚Šã¾ã—ãŸã€‚(17). ã‚„ã¾ã€€â‘ .ä¸Šã€€â‘¡.å±±ã€€â‘¢.æ­¢ã€€â‘£.å‡¸",
                "expected": "â‘¡",
                "test_name": "Basic Vocabulary - Mountain (å±±)"
            },
            {
                "question": "ã“ã‚“ã—ã‚…ã†ã¯ã€€ã¦ã‚“ããŒã€€ã‚ˆã‹ã£ãŸã€‚(18). ã“ã‚“ã—ã‚…ã†ã€€â‘ .ä»Šé€±ã€€â‘¡.ä»Šéã€€â‘¢.ä»¤é€±ã€€â‘£.ä»Šç¿’",
                "expected": "â‘ ",
                "test_name": "Time Expression - This Week (ä»Šé€±)"
            },
            {
                "question": "ã“ã‚“ã—ã‚…ã†ã¯ã€€ã¦ã‚“ããŒã€€ã‚ˆã‹ã£ãŸã€‚(19). ã¦ã‚“ãã€€â‘ .å¤©æ°—ã€€â‘¡.å¤©æ±½ã€€â‘¢.çŸ¢æ°—ã€€â‘£.è»¢æ°—",
                "expected": "â‘ ",
                "test_name": "Weather - Weather (å¤©æ°—)"
            },
            {
                "question": "ãã®ã€€ã¡ã„ã•ã„ã€€ã‹ã‚Œã‚“ã ãƒ¼ã‚’ã€€ãã ã•ã„ã€‚(20). ã¡ã„ã•ã„ã€€â‘ .å°ã„ã€€â‘¡.å°ã•ã„ã€€â‘¢.å°‘ã„ã€€â‘£.å°‘ã•ã„",
                "expected": "â‘¡",
                "test_name": "Adjective - Small (å°ã•ã„)"
            },
            {
                "question": "ãã®ã€€ã¡ã„ã•ã„ã€€ã‹ã‚Œã‚“ã ãƒ¼ã‚’ã€€ãã ã•ã„ã€‚(21). ã‹ã‚Œã‚“ã ãƒ¼ã€€â‘ .ã‚«ãƒˆãƒ³ã‚°ãƒ¼ã€€â‘¡.ã‚«ãƒˆãƒ³ãƒ€ãƒ¼ã€€â‘¢.ã‚«ãƒ¬ãƒ³ã‚°ãƒ¼ã€€â‘£.ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼",
                "expected": "â‘£",
                "test_name": "Katakana Loanword - Calendar (ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼)"
            },
            {
                "question": "ã²ãŒã—ã®ã€€ãã‚‰ãŒã€€ãã‚Œã„ã§ã™ã€‚(22). ã²ãŒã—ã€€â‘ .è¥¿ã€€â‘¡.æ±ã€€â‘¢.å—ã€€â‘£.åŒ—",
                "expected": "â‘¡",
                "test_name": "Direction - East (æ±)"
            },
            {
                "question": "ã²ãŒã—ã®ã€€ãã‚‰ãŒã€€ãã‚Œã„ã§ã™ã€‚(23). ãã‚‰ã€€â‘ .å·ã€€â‘¡.æ± ã€€â‘¢.ç©ºã€€â‘£.é¢¨",
                "expected": "â‘¢",
                "test_name": "Nature - Sky (ç©º)"
            },
            {
                "question": "ã‚€ã„ã‹ã®ã€€ã”ã”ã«ã€€ã‚ã„ã¾ã—ã‚‡ã†ã€‚(24). ã‚€ã„ã‹ã€€â‘ .ä¹æ—¥ã€€â‘¡.ä¸‰æ—¥ã€€â‘¢.å…­æ—¥ã€€â‘£.äº”æ—¥",
                "expected": "â‘¢",
                "test_name": "Date - Sixth Day (å…­æ—¥)"
            }
        ]
        
        # Run all tests
        for test_case in test_cases:
            self.run_test_case(
                test_case["question"],
                test_case["expected"],
                test_case["test_name"]
            )
            time.sleep(1)  # Prevent API rate limiting
        
        # Generate report
        self.generate_report()
    
    def generate_report(self):
        """Generate comprehensive test report"""
        print("\n" + "=" * 70)
        print("ğŸ¯ TEST RESULTS SUMMARY")
        print("=" * 70)
        
        total_tests = len(self.test_results)
        correct_answers = sum(1 for r in self.test_results if r["is_correct"])
        accuracy_rate = (correct_answers / total_tests) * 100 if total_tests > 0 else 0
        
        avg_processing_time = sum(r["processing_time"] for r in self.test_results) / total_tests if total_tests > 0 else 0
        
        print(f"ğŸ“Š Total Tests: {total_tests}")
        print(f"âœ… Correct Answers: {correct_answers}")
        print(f"âŒ Incorrect Answers: {total_tests - correct_answers}")
        print(f"ğŸ¯ Accuracy Rate: {accuracy_rate:.1f}%")
        print(f"âš¡ Average Processing Time: {avg_processing_time:.2f}s")
        
        # Detailed results
        print(f"\nğŸ“‹ DETAILED RESULTS:")
        print("-" * 70)
        
        for i, result in enumerate(self.test_results, 1):
            status_icon = "âœ…" if result["is_correct"] else "âŒ"
            print(f"{i:2d}. {status_icon} {result['test_name']}")
            print(f"    Expected: {result['expected']} | Actual: {result['actual']} | Time: {result['processing_time']:.2f}s")
        
        # Failed tests analysis
        failed_tests = [r for r in self.test_results if not r["is_correct"]]
        if failed_tests:
            print(f"\nâŒ FAILED TESTS ANALYSIS:")
            print("-" * 70)
            
            for test in failed_tests:
                print(f"\nğŸ” {test['test_name']}")
                print(f"   Question: {test['question'][:60]}...")
                print(f"   Expected: {test['expected']}")
                print(f"   Actual: {test['actual']}")
                print(f"   AI Response Preview: {test['ai_response'][:100]}...")
        
        # Performance analysis
        print(f"\nâš¡ PERFORMANCE ANALYSIS:")
        print("-" * 70)
        
        fastest = min(self.test_results, key=lambda r: r["processing_time"])
        slowest = max(self.test_results, key=lambda r: r["processing_time"])
        
        print(f"ğŸš€ Fastest Test: {fastest['test_name']} ({fastest['processing_time']:.2f}s)")
        print(f"ğŸŒ Slowest Test: {slowest['test_name']} ({slowest['processing_time']:.2f}s)")
        
        # Recommendations
        print(f"\nğŸ’¡ RECOMMENDATIONS:")
        print("-" * 70)
        
        if accuracy_rate < 80:
            print("âš ï¸  CRITICAL: Accuracy below 80% - Major improvements needed!")
            print("   - Review AI prompt engineering")
            print("   - Improve OCR preprocessing")
            print("   - Add context validation")
        elif accuracy_rate < 90:
            print("âš ï¸  WARNING: Accuracy below 90% - Improvements recommended")
            print("   - Fine-tune confidence thresholds")
            print("   - Add more validation rules")
        else:
            print("âœ… EXCELLENT: High accuracy achieved!")
            print("   - Continue monitoring performance")
            print("   - Consider edge case testing")
        
        if avg_processing_time > 10:
            print("âš ï¸  PERFORMANCE: Processing time is high")
            print("   - Optimize AI provider settings")
            print("   - Implement caching improvements")
        
        print(f"\nğŸŠ TEST COMPLETED AT: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 70)
    
    def export_results(self, filename: Optional[str] = None):
        """Export test results to JSON file"""
        import json
        
        if filename is None:
            filename = f"accuracy_test_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        export_data = {
            "test_metadata": {
                "timestamp": datetime.now().isoformat(),
                "total_tests": len(self.test_results),
                "accuracy_rate": (sum(1 for r in self.test_results if r["is_correct"]) / len(self.test_results)) * 100,
                "avg_processing_time": sum(r["processing_time"] for r in self.test_results) / len(self.test_results)
            },
            "test_results": self.test_results
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“„ Results exported to: {filename}")

def main():
    """Main test runner"""
    try:
        tester = AccuracyTester()
        tester.run_comprehensive_tests()
        
        # Export results
        response = input("\nğŸ’¾ Export results to file? (y/n): ").lower().strip()
        if response in ['y', 'yes']:
            tester.export_results()
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ Testing interrupted by user")
    except Exception as e:
        print(f"\nâŒ Test failed with error: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
